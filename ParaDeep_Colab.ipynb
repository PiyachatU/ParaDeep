{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiyachatU/ParaDeep/blob/main/ParaDeep_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5CPTFf-GgJ7"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1hKra9Eirlx69_cZMvPmjwfCAFx6Fhf0a\" alt=\"ParaDeep Icon\" width=\"200\"/>\n",
        "\n",
        "# ParaDeep: Sequence-Based Paratope Prediction with BiLSTM-CNN\n",
        "\n",
        "This notebook demonstrates how to use **ParaDeep**, a lightweight deep learning model for predicting paratope residues (antigen-binding sites) from antibody sequences. ParaDeep uses a BiLSTM-CNN architecture with learnable embeddings and requires only amino acid sequences — no structural input or large pretrained models.\n",
        "\n",
        "## What is ParaDeep?\n",
        "\n",
        "ParaDeep is a lightweight deep learning model for predicting paratope residues (antigen-binding sites) from antibody sequences. It uses a BiLSTM-CNN architecture with learnable embeddings and requires only amino acid sequences — no structural input or large pretrained models. The framework includes pretrained models for heavy (H), light (L), and combined (HL) chains. Predictions are per-residue, human-readable, and designed for practical use in early-stage antibody discovery and analysis.\n",
        "\n",
        "### Key Features:\n",
        "- **Sequence-only approach**: No structural data required\n",
        "- **Chain-aware modeling**: Specialized models for heavy (H), light (L), and combined (HL) chains\n",
        "- **Lightweight architecture**: Significantly reduced computing demands compared to structure-based or pretrained language models\n",
        "- **Per-residue predictions**: Binary classification of binding vs non-binding residues\n",
        "- **Simple input/output**: Uses CSV format for easy integration\n",
        "\n",
        "In this notebook, we'll set up the environment, download the necessary models, and run predictions on sample antibody sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCDvJk2GgJ-"
      },
      "source": [
        "## 1. Setup Environment\n",
        "\n",
        "First, let's install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rForSahdGgJ-"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnvwojPPGgJ_"
      },
      "source": [
        "## 2. Clone the ParaDeep Repository\n",
        "\n",
        "Now, let's clone the ParaDeep repository from GitHub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kbwNH6EGgJ_"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/PiyachatU/ParaDeep.git\n",
        "\n",
        "# Change to the ParaDeep directory\n",
        "%cd ParaDeep\n",
        "\n",
        "# List the contents of the repository\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tszWzbHZGgKA"
      },
      "source": [
        "## 3. Explore Repository Structure\n",
        "\n",
        "Let's examine the key components of the repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S40KKkrOGgKA"
      },
      "outputs": [],
      "source": [
        "# Check the model directory\n",
        "!ls -la model\n",
        "\n",
        "# Check the saved_models directory\n",
        "!ls -la saved_models\n",
        "\n",
        "# Check the data directory\n",
        "!ls -la data\n",
        "\n",
        "# Check the utils directory\n",
        "!ls -la utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dm3uVQ5GgKA"
      },
      "source": [
        "## 4. Examine Sample Input Format\n",
        "\n",
        "Let's look at the sample input format to understand what our data should look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6jpkFnGGgKA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load and display the sample input\n",
        "sample_input = pd.read_csv('data/sample_input.csv')\n",
        "sample_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGro_1hzGgKB"
      },
      "source": [
        "The input format requires:\n",
        "- **Seq_ID**: A unique identifier for each sequence\n",
        "- **Seq_cap**: The amino acid sequence in capital letters\n",
        "\n",
        "## 5. Create Our Own Input Data\n",
        "\n",
        "Let's create a custom input file with some example antibody sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un1S9tDwGgKB"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with example sequences\n",
        "custom_data = pd.DataFrame({\n",
        "    'Seq_ID': ['Heavy_Chain_1', 'Light_Chain_1'],\n",
        "    'Seq_cap': [\n",
        "        'EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAISGSGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKDLGWSDSYYYYYGMDVWGQGTTVTVSS',\n",
        "        'DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPPTFGQGTKVEIKR'\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Save to a CSV file\n",
        "custom_data.to_csv('data/custom_input.csv', index=False)\n",
        "\n",
        "# Display the custom data\n",
        "custom_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XubDtEAGgKB"
      },
      "source": [
        "## 6. Run Predictions\n",
        "\n",
        "Now, let's run predictions using the pretrained models. We'll try all three models: Heavy (H), Light (L), and Combined (HL)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6mARTzFGgKB"
      },
      "outputs": [],
      "source": [
        "# Run prediction with the Heavy chain model\n",
        "!python predict.py --model-path saved_models/ParaDeep_H.pt --input data/custom_input.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNnArCjxGgKC"
      },
      "outputs": [],
      "source": [
        "# Run prediction with the Light chain model\n",
        "!python predict.py --model-path saved_models/ParaDeep_L.pt --input data/custom_input.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IMWdo4PGgKC"
      },
      "outputs": [],
      "source": [
        "# Run prediction with the Combined (HL) model\n",
        "!python predict.py --model-path saved_models/ParaDeep_HL.pt --input data/custom_input.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dq7Y5B6GgKC"
      },
      "source": [
        "## 7. Examine the Results\n",
        "\n",
        "Let's look at the prediction results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jAcI-gqGgKC"
      },
      "outputs": [],
      "source": [
        "# List output files\n",
        "!ls -la output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pRf4dv0GgKC"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "# Get the most recent output files\n",
        "output_files = glob.glob('output/*.csv')\n",
        "output_files.sort(key=os.path.getmtime, reverse=True)\n",
        "\n",
        "# Load and display the H chain results\n",
        "h_results = pd.read_csv(output_files[2])  # Adjust index if needed\n",
        "h_results.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFUResayGgKD"
      },
      "outputs": [],
      "source": [
        "# Load and display the L chain results\n",
        "l_results = pd.read_csv(output_files[1])  # Adjust index if needed\n",
        "l_results.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpabkqOHGgKD"
      },
      "outputs": [],
      "source": [
        "# Load and display the HL chain results\n",
        "hl_results = pd.read_csv(output_files[0])  # Adjust index if needed\n",
        "hl_results.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me1u10EjGgKD"
      },
      "source": [
        "## 8. Visualize the Results\n",
        "\n",
        "Let's create a simple visualization of the predicted binding residues:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjMH85e3GgKD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_predictions(results_df, seq_id, pred_column):\n",
        "    # Filter for the specific sequence\n",
        "    seq_results = results_df[results_df['Seq_ID'] == seq_id]\n",
        "\n",
        "    # Extract positions and predictions\n",
        "    positions = seq_results['Residue_Position'].values\n",
        "    residues = seq_results['Residue'].values\n",
        "    predictions = seq_results[pred_column].values\n",
        "\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(15, 4))\n",
        "\n",
        "    # Plot predictions\n",
        "    plt.bar(positions, predictions, color='skyblue', alpha=0.7)\n",
        "    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Threshold (0.5)')\n",
        "\n",
        "    # Highlight binding residues\n",
        "    binding_positions = positions[predictions == 1]\n",
        "    binding_residues = residues[predictions == 1]\n",
        "    plt.scatter(binding_positions, np.ones(len(binding_positions)), color='red', s=100, label='Binding Residues')\n",
        "\n",
        "    # Add labels for binding residues\n",
        "    for pos, res in zip(binding_positions, binding_residues):\n",
        "        plt.text(pos, 1.05, res, ha='center', fontweight='bold')\n",
        "\n",
        "    # Set labels and title\n",
        "    plt.xlabel('Residue Position')\n",
        "    plt.ylabel('Binding Prediction (1 = binding)')\n",
        "    plt.title(f'Paratope Prediction for {seq_id}')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print sequence with binding residues highlighted\n",
        "    sequence = ''.join(residues)\n",
        "    highlighted_seq = ''\n",
        "    for i, res in enumerate(sequence):\n",
        "        if i+1 in binding_positions:\n",
        "            highlighted_seq += f\"[{res}]\"\n",
        "        else:\n",
        "            highlighted_seq += res\n",
        "\n",
        "    print(f\"Sequence with binding residues [highlighted]: \\n{highlighted_seq}\")\n",
        "    print(f\"\\nTotal residues: {len(sequence)}\")\n",
        "    print(f\"Binding residues: {len(binding_positions)} ({len(binding_positions)/len(sequence)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fed29ZX5GgKE"
      },
      "outputs": [],
      "source": [
        "# Visualize Heavy chain predictions\n",
        "visualize_predictions(h_results, 'Heavy_Chain_1', 'H_pred')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkWdtP1lGgKE"
      },
      "outputs": [],
      "source": [
        "# Visualize Light chain predictions\n",
        "visualize_predictions(l_results, 'Light_Chain_1', 'L_pred')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI5pfqqWGgKE"
      },
      "outputs": [],
      "source": [
        "# Visualize Combined (HL) chain predictions\n",
        "visualize_predictions(hl_results, 'Heavy_Chain_1', 'HL_pred')\n",
        "visualize_predictions(hl_results, 'Light_Chain_1', 'HL_pred')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SLwG7oBGgKE"
      },
      "source": [
        "## 9. Upload Your Own Sequences\n",
        "\n",
        "\n",
        "To use ParaDeep with your own antibody sequence data in Google Colab:\n",
        "\n",
        "1. Open Google Drive in a separate tab\n",
        "2. Create the following folder structure:\n",
        "\n",
        "*   `/MyDrive/ParaDeep/`\n",
        "*   `/MyDrive/ParaDeep/data/`\n",
        "\n",
        "3. Navigate to the /MyDrive/ParaDeep/data/ folder.\n",
        "\n",
        "4. Upload your CSV file to this folder. (An example file containing three sequences is available for download. https://github.com/PiyachatU/ParaDeep/blob/main/data/my_sequences.csv)\n",
        "\n",
        "5. Ensure your CSV has two columns:\n",
        "   - `Seq_ID`: unique sequence ID\n",
        "   - `Seq_cap`: amino acid sequence (e.g., \"EVQLVESGG...\")\n",
        "6. Then run the code cell below to load and process your file.\n",
        "7. Authorize Google Drive Access, when you run the next cell, a link will open asking for permission to access your Google Drive.**Please click “Allow” or “Select All” when asked**, otherwise the notebook may not be able to access your Drive properly.\n",
        "\n",
        "\n",
        "**Privacy & Security Notice**\n",
        "This notebook is safe to use and does **not access any data from your Google Drive** unless you explicitly run a code cell to do so. When you authorize Google Drive access (via `drive.mount()`), only **your own account** can see and interact with your files — **the notebook author or others cannot access your Drive data**.\n",
        "\n",
        "You remain in full control:\n",
        "- No data will be read from or written to your Drive without your action.\n",
        "- You can revoke access at any time via [https://myaccount.google.com/permissions](https://myaccount.google.com/permissions).\n",
        "- This notebook runs entirely in your private Colab session."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# STEP 2: Load your CSV from Google Drive\n",
        "csv_path = '/content/drive/MyDrive/ParaDeep/data/my_sequences.csv'\n",
        "\n",
        "def load_sequence_csv(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"File not found: {path}\")\n",
        "        return None\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        if 'Seq_ID' not in df.columns or 'Seq_cap' not in df.columns:\n",
        "            print(\"CSV must contain 'Seq_ID' and 'Seq_cap' columns.\")\n",
        "            return None\n",
        "        print(f\"Loaded file: {path}\")\n",
        "        display(df.head())\n",
        "        return df, path\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to read file: {e}\")\n",
        "        return None\n",
        "\n",
        "df_result = load_sequence_csv(csv_path)\n",
        "\n",
        "\n",
        "# STEP 3: Run ParaDeep Prediction with All Models and Save to Drive\n",
        "\n",
        "if df_result:\n",
        "    df, valid_path = df_result\n",
        "    print(\"Running ParaDeep on uploaded sequences using all models...\\n\")\n",
        "\n",
        "    model_list = [\n",
        "        'ParaDeep_HL.pt',\n",
        "        'ParaDeep_H.pt',\n",
        "        'ParaDeep_L.pt'\n",
        "    ]\n",
        "\n",
        "    output_dir = \"output\"\n",
        "    drive_output_dir = \"/content/drive/MyDrive/ParaDeep/results\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(drive_output_dir, exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
        "\n",
        "    for model_filename in model_list:\n",
        "        model_path = f'saved_models/{model_filename}'\n",
        "        model_tag = model_filename.replace('.pt', '').replace('ParaDeep_', '')  # 'H', 'L', or 'HL'\n",
        "\n",
        "        print(f\"Running model: {model_tag}\")\n",
        "        !python predict.py --model-path {model_path} --input {valid_path}\n",
        "\n",
        "        # Find the latest output file for the model\n",
        "        output_pattern = os.path.join(output_dir, f\"ParaDeep_{model_tag}_predictions_*.csv\")\n",
        "        output_files = sorted(glob(output_pattern), reverse=True)\n",
        "\n",
        "        if output_files:\n",
        "            latest_file = output_files[0]\n",
        "            output_filename = f\"ParaDeep_{model_tag}_predictions_{timestamp}.csv\"\n",
        "            drive_output_path = os.path.join(drive_output_dir, output_filename)\n",
        "\n",
        "            !cp {latest_file} {drive_output_path}\n",
        "            print(f\"Copied output for {model_tag} model to Google Drive: {drive_output_path}\")\n",
        "        else:\n",
        "            print(f\"No prediction file found for model: {model_tag}\")\n",
        "\n",
        "    print(\"\\nFinal contents of your Google Drive result folder:\")\n",
        "    !ls -lh {drive_output_dir}\n",
        "else:\n",
        "    print(\"Cannot proceed with prediction. CSV file was not loaded correctly.\")"
      ],
      "metadata": {
        "id": "0Eiz3G6VYUHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Imports and path setup\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "drive_output_dir = \"/content/drive/MyDrive/ParaDeep/results\"\n",
        "output_dir = \"output\"\n",
        "image_save_dir = os.path.join(output_dir, \"visualizations\")\n",
        "drive_vis_dir = \"/content/drive/MyDrive/ParaDeep/results/visualizations\"\n",
        "\n",
        "os.makedirs(image_save_dir, exist_ok=True)\n",
        "os.makedirs(drive_vis_dir, exist_ok=True)\n",
        "\n",
        "# STEP 5: Function to visualize one sequence\n",
        "def visualize_predictions(results_df, seq_id, pred_column, model_tag):\n",
        "    seq_results = results_df[results_df['Seq_ID'] == seq_id]\n",
        "    positions = seq_results['Residue_Position'].values\n",
        "    residues = seq_results['Residue'].values\n",
        "    predictions = seq_results[pred_column].values\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    plt.bar(positions, predictions, color='skyblue', alpha=0.7)\n",
        "    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Threshold (0.5)')\n",
        "\n",
        "    binding_positions = positions[predictions == 1]\n",
        "    binding_residues = residues[predictions == 1]\n",
        "    plt.scatter(binding_positions, np.ones(len(binding_positions)), color='red', s=100, label='Binding Residues')\n",
        "\n",
        "    for pos, res in zip(binding_positions, binding_residues):\n",
        "        plt.text(pos, 1.05, res, ha='center', fontweight='bold')\n",
        "\n",
        "    plt.xlabel('Residue Position')\n",
        "    plt.ylabel('Binding Prediction (1 = binding)')\n",
        "    plt.title(f'ParaDeep {model_tag} - Prediction for {seq_id}')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save before showing\n",
        "    fig_filename = f\"{model_tag}_{seq_id}_visualization.png\"\n",
        "    fig_path = os.path.join(image_save_dir, fig_filename)\n",
        "    plt.savefig(fig_path)\n",
        "    plt.show()\n",
        "    print(f\"Saved visualization to: {fig_path}\")\n",
        "\n",
        "    # Highlight residues\n",
        "    sequence = ''.join(residues)\n",
        "    highlighted_seq = ''\n",
        "    for i, res in enumerate(sequence):\n",
        "        if i+1 in binding_positions:\n",
        "            highlighted_seq += f\"[{res}]\"\n",
        "        else:\n",
        "            highlighted_seq += res\n",
        "\n",
        "    print(f\"Sequence with binding residues highlighted:\\n{highlighted_seq}\")\n",
        "    print(f\"Total residues: {len(sequence)}\")\n",
        "    print(f\"Binding residues: {len(binding_positions)} ({len(binding_positions)/len(sequence)*100:.1f}%)\\n\")\n",
        "\n",
        "# STEP 6: Visualize latest predictions from all models\n",
        "def visualize_all_model_predictions():\n",
        "    print(\"Scanning prediction files for all models...\\n\")\n",
        "    for model_tag in ['HL', 'H', 'L']:\n",
        "        pattern = os.path.join(drive_output_dir, f\"ParaDeep_{model_tag}_predictions_*.csv\")\n",
        "        model_files = sorted(glob(pattern), key=os.path.getctime, reverse=True)\n",
        "\n",
        "        if model_files:\n",
        "            latest_file = model_files[0]\n",
        "            print(f\"Loaded prediction file for model {model_tag}: {latest_file}\")\n",
        "            df = pd.read_csv(latest_file)\n",
        "\n",
        "            pred_column = f\"{model_tag}_pred\"\n",
        "            if pred_column not in df.columns:\n",
        "                print(f\"Column {pred_column} not found in file. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            for seq_id in df['Seq_ID'].unique():\n",
        "                visualize_predictions(df, seq_id, pred_column, model_tag)\n",
        "        else:\n",
        "            print(f\"No prediction output files found for model {model_tag}.\")\n",
        "\n",
        "# STEP 7: Run visualizations\n",
        "visualize_all_model_predictions()\n",
        "\n",
        "# STEP 8: Copy plots to Google Drive\n",
        "image_files = glob(os.path.join(image_save_dir, \"*.png\"))\n",
        "\n",
        "for img_path in image_files:\n",
        "    filename = os.path.basename(img_path)\n",
        "    target_path = os.path.join(drive_vis_dir, filename)\n",
        "    os.system(f'cp \"{img_path}\" \"{target_path}\"')\n"
      ],
      "metadata": {
        "id": "kB4VLEulSD2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I28TcwlGgKE"
      },
      "source": [
        "## 10. Understanding the Model Architecture\n",
        "\n",
        "ParaDeep uses a BiLSTM-CNN architecture to predict paratope residues:\n",
        "\n",
        "1. **Input**: Amino acid sequences are encoded using learnable embeddings\n",
        "2. **BiLSTM Layer**: Captures bidirectional context from the sequence\n",
        "3. **CNN Layer**: Extracts local features using sliding kernels\n",
        "4. **Output Layer**: Produces per-residue binding probabilities\n",
        "\n",
        "The model is trained with different kernel sizes for different chain types:\n",
        "- Heavy chain (H): Kernel size 9\n",
        "- Light chain (L): Kernel size 81\n",
        "- Combined chains (HL): Kernel size 21\n",
        "\n",
        "This chain-specific approach allows the model to capture the unique binding patterns of each chain type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp2r8wCSGgKF"
      },
      "source": [
        "## 11. Conclusion\n",
        "\n",
        "In this notebook, we've demonstrated how to use ParaDeep for predicting paratope residues from antibody sequences. The key advantages of ParaDeep include:\n",
        "\n",
        "- **Sequence-only approach**: No need for structural data\n",
        "- **Chain-specific modeling**: Specialized models for different chain types\n",
        "- **Lightweight architecture**: Efficient computation with minimal resources\n",
        "- **Interpretable results**: Clear per-residue binding predictions\n",
        "\n",
        "ParaDeep is particularly useful for early-stage antibody discovery and analysis when structural data may be limited or unavailable.\n",
        "\n",
        "### References\n",
        "\n",
        "- ParaDeep GitHub Repository: [https://github.com/PiyachatU/ParaDeep](https://github.com/PiyachatU/ParaDeep)\n",
        "- For more information on antibody paratope prediction methods, refer to the manuscript."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}