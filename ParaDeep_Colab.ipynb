{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2576501c",
      "metadata": {
        "id": "2576501c"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1hKra9Eirlx69_cZMvPmjwfCAFx6Fhf0a\" alt=\"ParaDeep Icon\" width=\"200\"/>\n",
        "\n",
        "# ParaDeep: Sequence-Based Paratope Prediction with BiLSTM-CNN\n",
        "**ParaDeep** is a lightweight, chain-aware deep learning framework for predicting **paratope residues** (antigen-binding sites) directly from antibody amino acid sequences. It employs a BiLSTM-CNN architecture with task-specific encodings—**learnable embeddings** for heavy (H) chains and **one-hot encoding** for light (L) chains—requiring no structural data or large pretrained models.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "##What is ParaDeep?\n",
        "ParaDeep was developed to enable **fast, interpretable, and accessible** paratope prediction in the early stages of antibody discovery. The model provides **per-residue binary predictions** (binding vs non-binding) and has been optimized for minimal computational overhead while maintaining competitive accuracy.\n",
        "\n",
        "The framework includes pretrained models for:\n",
        "*   Heavy (H) chains using embedding-based input\n",
        "*   Light (L) chains using one-hot encoding\n",
        "---\n",
        "##Key Features\n",
        "\n",
        "* Sequence-only input: No need for 3D structures or AlphaFold predictions\n",
        "* Chain-aware modeling: Independent models for H and L chains\n",
        "* Lightweight architecture: Suitable for local or Colab-based inference\n",
        "* Per-residue classification: Clear binary output per amino acid\n",
        "* User-friendly I/O: Reads .csv, .fasta, or .txt inputs and exports annotated .csv results\n",
        "---\n",
        "##What This Notebook Does\n",
        "In this notebook, you will:\n",
        "\n",
        "1. Set up the environment and install dependencies\n",
        "2. Download and load pretrained ParaDeep models\n",
        "3. Upload your antibody sequences\n",
        "4. Run predictions on both heavy and light chains\n",
        "5. Save and optionally visualize the results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xnvwojPPGgJ_",
      "metadata": {
        "id": "xnvwojPPGgJ_"
      },
      "source": [
        "## 1. Clone the ParaDeep Repository and setup environment\n",
        "\n",
        "First, let's clone the ParaDeep repository from GitHub and install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e63caa3",
      "metadata": {
        "id": "5e63caa3"
      },
      "outputs": [],
      "source": [
        "# Clone the repository and set up\n",
        "!git clone https://github.com/PiyachatU/ParaDeep.git\n",
        "%cd ParaDeep\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aHdxE2qjeerh",
      "metadata": {
        "id": "aHdxE2qjeerh"
      },
      "source": [
        "## 2. Examine Sample Input Format\n",
        "\n",
        "Let's look at the sample input format to understand what our data should look like:\n",
        "\n",
        "## Input Handling and Validation\n",
        "\n",
        "This block performs all necessary checks before running predictions with ParaDeep. It ensures that the input file format, content structure, and sequence properties meet the criteria required by the pipeline.\n",
        "\n",
        "### Supported Input Formats\n",
        "- `.csv` — must contain at least the following columns:\n",
        "  - `Seq_cap`: amino acid sequences\n",
        "  - `Chain_Type`: must be either `\"H\"` (heavy chain) or `\"L\"` (light chain)\n",
        "- `.fasta` / `.fa` — standard FASTA format (headers and sequences); parsed into `Seq_cap` and `Chain_Type` by `load_sequences()`\n",
        "- `.txt` — one sequence per line; chain type may be inferred or annotated in pre-processing\n",
        "\n",
        "### Automatically Checked Criteria\n",
        "\n",
        "1. **File Format and Parsing**  \n",
        "   - Format is detected from the file extension  \n",
        "   - All files are parsed using the `load_sequences()` function from `io_utils.py`  \n",
        "   - Returns a `pandas.DataFrame` with required columns\n",
        "\n",
        "2. **Column Validation**  \n",
        "   - The input must include both `Seq_cap` and `Chain_Type`  \n",
        "   - `Chain_Type` determines which model (H or L) to use for prediction\n",
        "\n",
        "3. **Sequence Validation**  \n",
        "   - All entries must be valid amino acid sequences (`str`)  \n",
        "   - The notebook reports:\n",
        "     - Minimum, maximum, and average sequence lengths\n",
        "     - Any sequences that exceed the maximum supported length (`MAX_SEQ_LEN = 130`)  \n",
        "   - Long sequences will be **automatically truncated or padded** before model input\n",
        "\n",
        "4. **Chain Type Distribution**  \n",
        "   - The notebook displays a count of how many H and L chain sequences are included  \n",
        "   - Ensures that predictions are properly routed to the corresponding pretrained model\n",
        "\n",
        "---\n",
        "### Notes:\n",
        "If any of these conditions are not met (e.g., missing columns, unsupported file format, or invalid sequences), the notebook will raise a clear and descriptive error message to guide correction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D6jpkFnGGgKA",
      "metadata": {
        "id": "D6jpkFnGGgKA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"src\")\n",
        "import os\n",
        "import pandas as pd\n",
        "from io_utils import load_sequences\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Specify your input file (can be .csv, .fasta, or .txt)\n",
        "input_file = \"data/sample_input.txt\"  # Change as needed\n",
        "print(f\" Loading sequences from: {input_file}\")\n",
        "\n",
        "# Step 2: Load as DataFrame (handles all supported formats)\n",
        "df = load_sequences(input_file)  # Unified loader for .csv, .fasta, .txt\n",
        "\n",
        "# Step 3: Validate required structure\n",
        "required_cols = {\"Seq_cap\", \"Chain_Type\"}\n",
        "if not required_cols.issubset(df.columns):\n",
        "    raise ValueError(f\" Input file must contain columns: {required_cols}\")\n",
        "\n",
        "# Extract sequences and chain labels\n",
        "sequences = df[\"Seq_cap\"].tolist()\n",
        "chain_types = df[\"Chain_Type\"].tolist()\n",
        "\n",
        "print(f\" Loaded {len(sequences)} sequence(s)\")\n",
        "\n",
        "# Step 4: Sequence length analysis\n",
        "MAX_SEQ_LEN = 130\n",
        "lengths = [len(seq) for seq in sequences]\n",
        "\n",
        "print(f\" Sequence lengths — Min: {min(lengths)}, Max: {max(lengths)}, Avg: {sum(lengths) // len(lengths)}\")\n",
        "\n",
        "long_seqs = [i for i, l in enumerate(lengths) if l > MAX_SEQ_LEN]\n",
        "if long_seqs:\n",
        "    print(f\" {len(long_seqs)} sequence(s) exceed MAX_SEQ_LEN = {MAX_SEQ_LEN} — they will be truncated or padded during prediction.\")\n",
        "else:\n",
        "    print(\" All sequences are within the length limit.\")\n",
        "\n",
        "# Step 5: Report Chain Type Distribution (H vs L)\n",
        "type_counts = Counter(chain_types)\n",
        "print(f\" Chain Type Distribution: {dict(type_counts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s5G9nZHh8DFL",
      "metadata": {
        "id": "s5G9nZHh8DFL"
      },
      "source": [
        "## 3. Running ParaDeep Predictions\n",
        "The following command runs the ParaDeep model on a user-provided sequence file. It uses **two pretrained models**: one for the heavy chain (H) and one for the light chain (L). ParaDeep automatically detects which chain each sequence belongs to and applies the appropriate model.\n",
        "\n",
        "### **Example Command:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RAEaJVpMbIcz",
      "metadata": {
        "id": "RAEaJVpMbIcz"
      },
      "outputs": [],
      "source": [
        "!python paradeep.py \\\n",
        "  --input data/sample_input.csv \\\n",
        "  --modelH models/Best_Model_H.pt \\\n",
        "  --modelL models/Best_Model_L.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gFcDMqjS6CVJ",
      "metadata": {
        "id": "gFcDMqjS6CVJ"
      },
      "source": [
        "## 4. Visualization of Paratope Predictions\n",
        "This section automatically visualizes the predicted paratope residues using per-residue binding probabilities.\n",
        "\n",
        "### Key Features:\n",
        "* Bar chart shows the probability of each residue being part of a paratope\n",
        "* Red scatter dots highlight predicted binding residues (Prediction = 1)\n",
        "* Amino acid labels are displayed at a fixed height for clarity\n",
        "* Threshold line at 0.5 marks the decision boundary used for classification\n",
        "\n",
        "### What It Detects Automatically:\n",
        "1. **Latest Prediction File**\n",
        "The script scans the /output folder and selects the most recent predictions file.\n",
        "2. **Sequence IDs and Chain Types**\n",
        "It automatically identifies unique sequences (Seq_ID) and checks for both heavy (H) and light (L) chain prediction columns.\n",
        "3. **Per-Chain Visualization**\n",
        "For each sequence, a separate chart is created for the H and/or L chain (if present).\n",
        "\n",
        "### Example Output\n",
        "* X-axis: Residue positions (1-based)\n",
        "* Y-axis: Probability of being a binding residue (range: 0.0–1.0)\n",
        "* Threshold at 0.5 is used to binarize predictions\n",
        "* Binding residues are marked with both color and label (e.g., [Y])\n",
        "---\n",
        "### Notes:\n",
        "* Only residues with Prediction = 1 are annotated above the bar\n",
        "* Long sequences are auto-scaled\n",
        "* Text highlights below the plot indicate binding positions in square brackets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IB5F303g4XkB",
      "metadata": {
        "id": "IB5F303g4XkB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "def visualize_latest_paradeep_predictions(save_dir=\"output/figures\"):\n",
        "    \"\"\"\n",
        "    Automatically finds the latest ParaDeep predictions file,\n",
        "    and visualizes predicted binding residues for H and L chains.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Step 1: Load latest prediction file\n",
        "    prediction_files = sorted(glob(\"output/predictions_*.csv\"), key=os.path.getmtime, reverse=True)\n",
        "    if not prediction_files:\n",
        "        print(\" No prediction files found in 'output/'\")\n",
        "        return\n",
        "    latest_file = prediction_files[0]\n",
        "    print(f\" Using latest prediction file: {latest_file}\")\n",
        "\n",
        "    df = pd.read_csv(latest_file)\n",
        "    if 'Seq_ID' not in df.columns or 'Chain_Type' not in df.columns:\n",
        "        print(\" Missing required columns ('Seq_ID' or 'Chain_Type') in prediction file.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Visualize each sequence by its chain type (H or L)\n",
        "    for chain in ['H', 'L']:\n",
        "        pred_col = f\"{chain}_Prediction\"\n",
        "        prob_col = f\"{chain}_Probability\"\n",
        "\n",
        "        if pred_col not in df.columns or prob_col not in df.columns:\n",
        "            continue  # Skip if predictions for this chain are not present\n",
        "\n",
        "        chain_df = df[df['Chain_Type'].str.upper() == chain]\n",
        "        for seq_id in chain_df['Seq_ID'].unique():\n",
        "            df_seq = chain_df[chain_df['Seq_ID'] == seq_id]\n",
        "            if df_seq.empty:\n",
        "                continue\n",
        "\n",
        "            # Extract values\n",
        "            positions = df_seq['Residue_Position'].values\n",
        "            residues = df_seq['Residue'].values\n",
        "            probabilities = df_seq[prob_col].values\n",
        "            predictions = df_seq[pred_col].astype(int).values\n",
        "\n",
        "            # Plot\n",
        "            plt.figure(figsize=(15, 4))\n",
        "            plt.bar(positions, probabilities, color='skyblue', alpha=0.7)\n",
        "            plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Threshold (0.5)')\n",
        "            plt.scatter(positions[predictions == 1], probabilities[predictions == 1],\n",
        "                        color='red', s=100, label='Binding Residues')\n",
        "\n",
        "            # Label only predicted binding residues\n",
        "            for p, res in zip(positions[predictions == 1], residues[predictions == 1]):\n",
        "                plt.text(p, 1.05, res, ha='center', fontweight='bold')\n",
        "\n",
        "            plt.title(f\"Paratope Prediction: {seq_id} ({chain}-chain)\")\n",
        "            plt.xlabel(\"Residue Position\")\n",
        "            plt.ylabel(\"Binding Probability\")\n",
        "            plt.ylim(0, 1.15)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Save figure\n",
        "            fig_path = os.path.join(save_dir, f\"{seq_id}_{chain}.png\")\n",
        "            plt.savefig(fig_path)\n",
        "            plt.show()\n",
        "            print(f\" Saved visualization to: {fig_path}\")\n",
        "\n",
        "            # Highlight residues\n",
        "            highlighted_seq = ''.join([f\"[{r}]\" if pred == 1 else r for r, pred in zip(residues, predictions)])\n",
        "            print(f\" Highlighted Sequence ({seq_id}):\\n{highlighted_seq}\\n\")\n",
        "\n",
        "# ✅ Run the visualization\n",
        "visualize_latest_paradeep_predictions()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lmYkWFjp8nLB",
      "metadata": {
        "id": "lmYkWFjp8nLB"
      },
      "source": [
        "## 6. Upload Your Own Sequences\n",
        "\n",
        "\n",
        "To use ParaDeep with your own antibody sequence data in Google Colab:\n",
        "\n",
        "1. Open Google Drive in a separate tab\n",
        "2. Create the following folder structure:\n",
        "\n",
        "*   `/MyDrive/ParaDeep/`\n",
        "*   `/MyDrive/ParaDeep/data/`\n",
        "\n",
        "3. Navigate to the /MyDrive/ParaDeep/data/ folder.\n",
        "\n",
        "4. Upload your CSV file to this folder. (An example file containing three sequences is available for download. https://github.com/PiyachatU/ParaDeep/blob/main/data/my_sequences.csv)\n",
        "\n",
        "5. Ensure your CSV has two columns:\n",
        "   - `Seq_ID`: unique sequence ID\n",
        "   - `Chain_Type`: chain type\n",
        "   - `Seq_cap`: amino acid sequence (e.g., \"EVQLVESGG...\")\n",
        "6. Then run the code cell below to load and process your file.\n",
        "7. Authorize Google Drive Access, when you run the next cell, a link will open asking for permission to access your Google Drive.**Please click “Allow” or “Select All” when asked**, otherwise the notebook may not be able to access your Drive properly.\n",
        "\n",
        "\n",
        "**Privacy & Security Notice**\n",
        "This notebook is safe to use and does **not access any data from your Google Drive** unless you explicitly run a code cell to do so. When you authorize Google Drive access (via `drive.mount()`), only **your own account** can see and interact with your files — **the notebook author or others cannot access your Drive data**.\n",
        "\n",
        "You remain in full control:\n",
        "- No data will be read from or written to your Drive without your action.\n",
        "- You can revoke access at any time via [https://myaccount.google.com/permissions](https://myaccount.google.com/permissions).\n",
        "- This notebook runs entirely in your private Colab session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fBmYckJVtH1M",
      "metadata": {
        "id": "fBmYckJVtH1M"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# STEP 2: Load input file (CSV, FASTA, or TXT)\n",
        "sys.path.append(\"src\")\n",
        "from io_utils import load_sequences\n",
        "\n",
        "input_path = '/content/drive/MyDrive/ParaDeep/data/my_sequences.csv'  # Change as needed\n",
        "\n",
        "def load_sequence_file(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"File not found: {path}\")\n",
        "        return None\n",
        "\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    try:\n",
        "        if ext == '.csv':\n",
        "            df = pd.read_csv(path)\n",
        "            if 'Seq_cap' not in df.columns:\n",
        "                raise ValueError(\"CSV must contain 'Seq_cap' column.\")\n",
        "            if 'Chain_Type' not in df.columns:\n",
        "                raise ValueError(\"CSV must contain 'Chain_Type' column.\")\n",
        "        else:\n",
        "            # Load raw sequences\n",
        "            sequences = load_sequences(path)\n",
        "            if not isinstance(sequences, list) or not all(isinstance(s, str) for s in sequences):\n",
        "                raise ValueError(\"Parsed data must be a list of amino acid sequences (strings).\")\n",
        "\n",
        "            # Infer chain type from filename\n",
        "            fname = os.path.basename(path).lower()\n",
        "            if 'heavy' in fname or '_h' in fname:\n",
        "                chain_type = 'H'\n",
        "            elif 'light' in fname or '_l' in fname:\n",
        "                chain_type = 'L'\n",
        "            else:\n",
        "                raise ValueError(\"Could not infer Chain_Type from filename. Use _H or _L in name.\")\n",
        "\n",
        "            # Build DataFrame\n",
        "            df = pd.DataFrame({\n",
        "                'Seq_ID': [f\"{chain_type}_seq_{i+1}\" for i in range(len(sequences))],\n",
        "                'Seq_cap': sequences,\n",
        "                'Chain_Type': chain_type\n",
        "            })\n",
        "\n",
        "        print(f\" Loaded {len(df)} sequence(s) from: {path}\")\n",
        "        display(df.head())\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to parse file: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run loading\n",
        "df_result = load_sequence_file(input_path)\n",
        "\n",
        "# STEP 4: Visualization with figure saving\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_predictions_save(df, seq_id, chain, save_dir=\"/content/drive/MyDrive/ParaDeep/results/figures\"):\n",
        "    \"\"\"\n",
        "    Visualizes and saves ParaDeep prediction results for a given sequence and chain type.\n",
        "    Only visualizes if chain type matches the model used.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    #  Check chain match from 'Chain_Type' column\n",
        "    seq_chain_type = df[df['Seq_ID'] == seq_id]['Chain_Type'].dropna().unique()\n",
        "    if len(seq_chain_type) != 1:\n",
        "        print(f\" Skipping {seq_id}: Unable to determine unique Chain_Type.\")\n",
        "        return\n",
        "\n",
        "    if seq_chain_type[0].upper() != chain.upper():\n",
        "        print(f\" Skipping {seq_id}: Chain_Type is '{seq_chain_type[0]}', not '{chain}'.\")\n",
        "        return\n",
        "\n",
        "    #  Check prediction columns\n",
        "    prob_col = f\"{chain}_Probability\"\n",
        "    pred_col = f\"{chain}_Prediction\"\n",
        "\n",
        "    if prob_col not in df.columns or pred_col not in df.columns:\n",
        "        print(f\" Columns for chain '{chain}' not found in DataFrame.\")\n",
        "        return\n",
        "\n",
        "    #  Extract prediction results\n",
        "    df_seq = df[(df['Seq_ID'] == seq_id) & (~df[pred_col].isna())]\n",
        "    if df_seq.empty:\n",
        "        print(f\" No prediction data for {seq_id} ({chain}-chain). Skipping.\")\n",
        "        return\n",
        "\n",
        "    pos = df_seq['Residue_Position'].values\n",
        "    aa = df_seq['Residue'].values\n",
        "    prob = df_seq[prob_col].values\n",
        "    pred = df_seq[pred_col].astype(int).values\n",
        "\n",
        "    #  Plotting\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    plt.bar(pos, prob, color='skyblue', alpha=0.7)\n",
        "    plt.axhline(y=0.5, color='red', linestyle='--', label='Threshold')\n",
        "    plt.scatter(pos[pred == 1], prob[pred == 1], color='red', s=100, label='Binding Residues')\n",
        "    for p, r in zip(pos[pred == 1], aa[pred == 1]):\n",
        "        plt.text(p, 1.05, r, ha='center', fontweight='bold')\n",
        "\n",
        "    plt.title(f\"ParaDeep {chain}-Chain Prediction: {seq_id}\")\n",
        "    plt.xlabel(\"Residue Position\")\n",
        "    plt.ylabel(\"Binding Probability\")\n",
        "    plt.ylim(0, 1.15)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save and show\n",
        "    fig_path = os.path.join(save_dir, f\"{seq_id}_{chain}.png\")\n",
        "    plt.savefig(fig_path)\n",
        "    plt.show()\n",
        "    print(f\" Saved visualization to: {fig_path}\")\n",
        "\n",
        "# STEP 5: Load result and visualize only matching chain-model pairs\n",
        "results = sorted(glob(os.path.join(\"output\", 'predictions_*.csv')), reverse=True)\n",
        "if results:\n",
        "    latest = results[0]\n",
        "    df = pd.read_csv(latest)\n",
        "\n",
        "    for chain in ['H', 'L']:\n",
        "        pred_col = f\"{chain}_Prediction\"\n",
        "        if pred_col in df.columns:\n",
        "            #  Iterate only sequences of the same chain type\n",
        "            matching_ids = df[df['Chain_Type'].str.upper() == chain.upper()]['Seq_ID'].unique()\n",
        "            for seq_id in matching_ids:\n",
        "                visualize_predictions_save(df, seq_id, chain)\n",
        "else:\n",
        "    print(\" No prediction result found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QkSfIlGv8pLg",
      "metadata": {
        "id": "QkSfIlGv8pLg"
      },
      "source": [
        "### References\n",
        "\n",
        "- ParaDeep GitHub Repository: [https://github.com/PiyachatU/ParaDeep](https://github.com/PiyachatU/ParaDeep)\n",
        "- For more information on antibody paratope prediction methods, refer to the manuscript."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
