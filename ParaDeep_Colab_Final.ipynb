{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üß¨ ParaDeep: Sequence-Based Paratope Prediction with BiLSTM-CNN\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PiyachatU/ParaDeep/blob/main/ParaDeep_Colab_Final.ipynb)\n",
        "\n",
        "**ParaDeep** is a lightweight, chain-aware deep learning framework for predicting **paratope residues** (antigen-binding sites) directly from antibody amino acid sequences. It employs a BiLSTM-CNN architecture with task-specific encodings‚Äî**learnable embeddings** for heavy (H) chains and **one-hot encoding** for light (L) chains‚Äîrequiring no structural data or large pretrained models.\n",
        "\n",
        "## üéØ What is ParaDeep?\n",
        "\n",
        "ParaDeep was developed to enable **fast, interpretable, and accessible** paratope prediction in the early stages of antibody discovery. The model provides **per-residue binary predictions** (binding vs non-binding) and has been optimized for minimal computational overhead while maintaining competitive accuracy.\n",
        "\n",
        "### Key Features:\n",
        "- üî¨ **Sequence-only input**: No need for 3D structures or AlphaFold predictions\n",
        "- ‚ö° **Chain-aware modeling**: Independent models for H and L chains\n",
        "- üöÄ **Lightweight architecture**: Suitable for local or Colab-based inference\n",
        "- üìä **Per-residue classification**: Clear binary output per amino acid\n",
        "- üìÅ **User-friendly I/O**: Direct sequence input or file upload\n",
        "\n",
        "### What This Notebook Does:\n",
        "1. üõ†Ô∏è Set up the environment and install dependencies\n",
        "2. üì• Download and load pretrained ParaDeep models\n",
        "3. üì§ Input your H and L chain sequences directly\n",
        "4. üîÆ Run predictions on both heavy and light chains\n",
        "5. üíæ Save and visualize the results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. üõ†Ô∏è Environment Setup\n",
        "\n",
        "First, let's clone the ParaDeep repository from GitHub and install the required dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup_code",
      "metadata": {
        "id": "setup_code"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Check if we're in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üîç Running in Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"üîç Running in local environment\")\n",
        "\n",
        "# Clone the repository if not already present\n",
        "if not os.path.exists('ParaDeep'):\n",
        "    print(\"üì• Cloning ParaDeep repository...\")\n",
        "    !git clone https://github.com/PiyachatU/ParaDeep.git\n",
        "    print(\"‚úÖ Repository cloned successfully\")\n",
        "else:\n",
        "    print(\"‚úÖ ParaDeep repository already exists\")\n",
        "\n",
        "# Change to the ParaDeep directory\n",
        "os.chdir('ParaDeep')\n",
        "print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Install requirements\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# Add src to Python path\n",
        "sys.path.insert(0, os.path.join(os.getcwd(), \"src\"))\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    from tqdm import tqdm\n",
        "    from Bio import SeqIO\n",
        "    from datetime import datetime\n",
        "    print(\"‚úÖ All dependencies installed successfully\")\n",
        "    print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "    print(f\"üñ•Ô∏è  Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing dependencies: {e}\")\n",
        "    print(\"Please restart the runtime and try again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sequence_input",
      "metadata": {
        "id": "sequence_input"
      },
      "source": [
        "## 2. üì§ Input Your Antibody Sequences\n",
        "\n",
        "Enter your Heavy (H) and Light (L) chain sequences below. The system will validate your sequences and run predictions automatically.\n",
        "\n",
        "### Requirements:\n",
        "- **Heavy Chain (H)**: Variable heavy chain sequence\n",
        "- **Light Chain (L)**: Variable light chain sequence (kappa or lambda)\n",
        "- **Format**: Standard single-letter amino acid codes (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y)\n",
        "- **Length**: Up to 130 residues (longer sequences will be truncated)\n",
        "\n",
        "### Example Sequences:\n",
        "- **H-chain**: `EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAISGSGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAR`\n",
        "- **L-chain**: `DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKLLIYAASTLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQRYNRAPYTFGQGTKVEIK`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sequence_input_interface",
      "metadata": {
        "id": "sequence_input_interface"
      },
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "from src.io_utils import load_sequences\n",
        "from src.core import predict_paradeep\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üß¨ Enter your antibody sequences below:\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìù ANTIBODY SEQUENCE INPUT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get user input for sequences\n",
        "print(\"\\nüîó Heavy Chain (H) Sequence:\")\n",
        "print(\"   Paste your heavy chain variable region sequence below\")\n",
        "print(\"   Example: EVQLVESGGGLVQPGGSLRLSCAASGFTFS...\")\n",
        "h_sequence = input(\"H-chain: \").strip().upper()\n",
        "\n",
        "print(\"\\nüîó Light Chain (L) Sequence:\")\n",
        "print(\"   Paste your light chain variable region sequence below\")\n",
        "print(\"   Example: DIQMTQSPSSLSASVGDRVTITC...\")\n",
        "l_sequence = input(\"L-chain: \").strip().upper()\n",
        "\n",
        "# Optional: Sequence ID\n",
        "print(\"\\nüè∑Ô∏è  Sequence ID (optional):\")\n",
        "print(\"   Enter a name/ID for your antibody (default: 'MyAntibody')\")\n",
        "seq_id = input(\"Seq ID: \").strip()\n",
        "if not seq_id:\n",
        "    seq_id = \"MyAntibody\"\n",
        "\n",
        "# Validate and process sequences\n",
        "def validate_sequence(seq, chain_type):\n",
        "    \"\"\"Validate amino acid sequence\"\"\"\n",
        "    if not seq:\n",
        "        return False, f\"‚ùå {chain_type}-chain sequence is empty\"\n",
        "    \n",
        "    # Check for valid amino acids\n",
        "    valid_aa = set(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "    invalid_chars = set(seq) - valid_aa\n",
        "    \n",
        "    if invalid_chars:\n",
        "        return False, f\"‚ùå {chain_type}-chain contains invalid characters: {sorted(invalid_chars)}\"\n",
        "    \n",
        "    # Check length\n",
        "    if len(seq) > 130:\n",
        "        return True, f\"‚ö†Ô∏è  {chain_type}-chain sequence is {len(seq)} residues (will be truncated to 130)\"\n",
        "    \n",
        "    return True, f\"‚úÖ {chain_type}-chain sequence is valid ({len(seq)} residues)\"\n",
        "\n",
        "# Validate sequences\n",
        "print(\"\\nüîç Validating sequences...\")\n",
        "sequences_to_process = []\n",
        "\n",
        "if h_sequence:\n",
        "    h_valid, h_msg = validate_sequence(h_sequence, \"Heavy\")\n",
        "    print(h_msg)\n",
        "    if h_valid:\n",
        "        sequences_to_process.append({\n",
        "            'Seq_ID': seq_id,\n",
        "            'Chain_Type': 'H',\n",
        "            'Seq_cap': h_sequence\n",
        "        })\n",
        "\n",
        "if l_sequence:\n",
        "    l_valid, l_msg = validate_sequence(l_sequence, \"Light\")\n",
        "    print(l_msg)\n",
        "    if l_valid:\n",
        "        sequences_to_process.append({\n",
        "            'Seq_ID': seq_id,\n",
        "            'Chain_Type': 'L',\n",
        "            'Seq_cap': l_sequence\n",
        "        })\n",
        "\n",
        "# Process sequences if valid\n",
        "if sequences_to_process:\n",
        "    print(f\"\\n‚úÖ Ready to process {len(sequences_to_process)} sequence(s)\")\n",
        "    \n",
        "    # Create DataFrame\n",
        "    user_df = pd.DataFrame(sequences_to_process)\n",
        "    \n",
        "    # Save to file\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    input_filename = f\"data/user_input_{timestamp}.csv\"\n",
        "    user_df.to_csv(input_filename, index=False)\n",
        "    \n",
        "    print(f\"üíæ Sequences saved to: {input_filename}\")\n",
        "    print(\"\\nüìã Your sequences:\")\n",
        "    for _, row in user_df.iterrows():\n",
        "        print(f\"   {row['Chain_Type']}-chain ({len(row['Seq_cap'])} residues): {row['Seq_cap'][:50]}...\")\n",
        "    \n",
        "    # Automatically run predictions\n",
        "    print(\"\\nüöÄ Running ParaDeep predictions on your sequences...\")\n",
        "    \n",
        "    # Set up output paths\n",
        "    output_file = f\"output/user_predictions_{timestamp}.csv\"\n",
        "    plot_dir = f\"output/user_plots_{timestamp}\"\n",
        "    \n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(\"output\", exist_ok=True)\n",
        "    os.makedirs(plot_dir, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        # Run predictions\n",
        "        predict_paradeep(\n",
        "            input_path=input_filename,\n",
        "            model_H_path=\"models/Best_Model_H.pt\",\n",
        "            model_L_path=\"models/Best_Model_L.pt\",\n",
        "            kernel_H='Full',\n",
        "            kernel_L='Full',\n",
        "            output_path=output_file,\n",
        "            visualize=True,\n",
        "            plot_dir=plot_dir\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nüéâ Predictions completed successfully!\")\n",
        "        print(f\"üìä Results saved to: {output_file}\")\n",
        "        print(f\"üé® Visualizations saved to: {plot_dir}\")\n",
        "        \n",
        "        # Display results summary\n",
        "        if os.path.exists(output_file):\n",
        "            results_df = pd.read_csv(output_file)\n",
        "            \n",
        "            print(f\"\\nüìà Results Summary:\")\n",
        "            for chain in ['H', 'L']:\n",
        "                pred_col = f\"{chain}_Prediction\"\n",
        "                if pred_col in results_df.columns:\n",
        "                    chain_data = results_df[results_df['Chain_Type'] == chain]\n",
        "                    if not chain_data.empty:\n",
        "                        binding_count = chain_data[pred_col].sum()\n",
        "                        total_count = len(chain_data)\n",
        "                        percentage = (binding_count / total_count) * 100\n",
        "                        print(f\"   üîó {chain}-chain: {binding_count}/{total_count} binding residues ({percentage:.1f}%)\")\n",
        "                        \n",
        "                        # Show binding residues\n",
        "                        binding_residues = chain_data[chain_data[pred_col] == 1]\n",
        "                        if not binding_residues.empty:\n",
        "                            positions = binding_residues['Residue_Position'].tolist()\n",
        "                            residues = binding_residues['Residue'].tolist()\n",
        "                            binding_info = [f\"{res}{pos}\" for res, pos in zip(residues, positions)]\n",
        "                            print(f\"      Binding sites: {', '.join(binding_info)}\")\n",
        "                            \n",
        "                            # Create highlighted sequence\n",
        "                            sequence = ''.join(chain_data['Residue'].tolist())\n",
        "                            predictions = chain_data[pred_col].tolist()\n",
        "                            highlighted = ''.join([f\"[{r}]\" if p == 1 else r for r, p in zip(sequence, predictions)])\n",
        "                            print(f\"      Highlighted: {highlighted}\")\n",
        "        \n",
        "        # Download option for Colab\n",
        "        if IN_COLAB:\n",
        "            print(f\"\\nüì• Download your results:\")\n",
        "            from google.colab import files\n",
        "            files.download(output_file)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during prediction: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "else:\n",
        "    print(\"\\n‚ùå No valid sequences to process. Please check your input and try again.\")\n",
        "    print(\"\\nüí° Tips:\")\n",
        "    print(\"   - Use only standard amino acid letters (A-Z, no numbers or special characters)\")\n",
        "    print(\"   - Make sure sequences are not empty\")\n",
        "    print(\"   - Variable region sequences typically range from 100-130 residues\")\n",
        "    print(\"   - You can input just H-chain, just L-chain, or both\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "visualization",
      "metadata": {
        "id": "visualization"
      },
      "source": [
        "## 3. üìä Enhanced Results Visualization\n",
        "\n",
        "Create detailed visualizations of your paratope predictions with binding residue highlighting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "visualization_code",
      "metadata": {
        "id": "visualization_code"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "def create_enhanced_visualization(save_dir=\"output/enhanced_figures\"):\n",
        "    \"\"\"\n",
        "    Create enhanced visualizations of ParaDeep predictions\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    \n",
        "    # Find latest prediction file\n",
        "    prediction_files = sorted(glob(\"output/*predictions_*.csv\"), key=os.path.getmtime, reverse=True)\n",
        "    if not prediction_files:\n",
        "        print(\"‚ùå No prediction files found in 'output/'\")\n",
        "        print(\"Please run predictions first using the cell above.\")\n",
        "        return\n",
        "    \n",
        "    latest_file = prediction_files[0]\n",
        "    print(f\"üìä Using prediction file: {latest_file}\")\n",
        "    \n",
        "    df = pd.read_csv(latest_file)\n",
        "    \n",
        "    # Validate required columns\n",
        "    required_cols = ['Seq_ID', 'Chain_Type', 'Residue_Position', 'Residue']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"‚ùå Missing required columns in prediction file\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üìà Creating visualizations for {df['Seq_ID'].nunique()} unique sequences...\")\n",
        "    \n",
        "    # Process each chain type\n",
        "    for chain in ['H', 'L']:\n",
        "        pred_col = f\"{chain}_Prediction\"\n",
        "        prob_col = f\"{chain}_Probability\"\n",
        "        \n",
        "        if pred_col not in df.columns or prob_col not in df.columns:\n",
        "            continue\n",
        "        \n",
        "        chain_df = df[df['Chain_Type'].str.upper() == chain]\n",
        "        if chain_df.empty:\n",
        "            continue\n",
        "            \n",
        "        print(f\"\\nüîó Processing {chain}-chain sequences...\")\n",
        "        \n",
        "        for seq_id in chain_df['Seq_ID'].unique():\n",
        "            df_seq = chain_df[chain_df['Seq_ID'] == seq_id].sort_values('Residue_Position')\n",
        "            \n",
        "            if df_seq.empty:\n",
        "                continue\n",
        "            \n",
        "            # Extract data\n",
        "            positions = df_seq['Residue_Position'].values\n",
        "            residues = df_seq['Residue'].values\n",
        "            probabilities = df_seq[prob_col].values\n",
        "            predictions = df_seq[pred_col].astype(int).values\n",
        "            \n",
        "            # Create enhanced plot\n",
        "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8), \n",
        "                                         gridspec_kw={'height_ratios': [3, 1]})\n",
        "            \n",
        "            # Main probability plot\n",
        "            bars = ax1.bar(positions, probabilities, \n",
        "                          color=['#ff6b6b' if p == 1 else '#4ecdc4' for p in predictions],\n",
        "                          alpha=0.7, edgecolor='black', linewidth=0.5)\n",
        "            \n",
        "            # Threshold line\n",
        "            ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.8, \n",
        "                       linewidth=2, label='Decision Threshold (0.5)')\n",
        "            \n",
        "            # Highlight binding residues\n",
        "            binding_mask = predictions == 1\n",
        "            if np.any(binding_mask):\n",
        "                ax1.scatter(positions[binding_mask], probabilities[binding_mask],\n",
        "                           color='darkred', s=100, zorder=5, \n",
        "                           label=f'Binding Residues ({np.sum(binding_mask)})', \n",
        "                           marker='o', edgecolor='white', linewidth=2)\n",
        "                \n",
        "                # Label binding residues\n",
        "                for pos, res, prob in zip(positions[binding_mask], \n",
        "                                        residues[binding_mask], \n",
        "                                        probabilities[binding_mask]):\n",
        "                    ax1.annotate(res, (pos, prob), \n",
        "                               xytext=(0, 15), textcoords='offset points',\n",
        "                               ha='center', va='bottom', fontweight='bold',\n",
        "                               fontsize=10, color='darkred',\n",
        "                               bbox=dict(boxstyle='round,pad=0.3', \n",
        "                                       facecolor='yellow', alpha=0.7))\n",
        "            \n",
        "            # Formatting\n",
        "            ax1.set_title(f\"Paratope Prediction: {seq_id} ({chain}-chain)\", \n",
        "                         fontsize=16, fontweight='bold', pad=20)\n",
        "            ax1.set_ylabel(\"Binding Probability\", fontsize=12, fontweight='bold')\n",
        "            ax1.set_ylim(0, 1.2)\n",
        "            ax1.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
        "            ax1.legend(loc='upper right', fontsize=10)\n",
        "            \n",
        "            # Sequence visualization\n",
        "            colors = ['red' if p == 1 else 'lightgray' for p in predictions]\n",
        "            ax2.bar(positions, [1]*len(positions), color=colors, alpha=0.8)\n",
        "            \n",
        "            # Add residue labels\n",
        "            for pos, res in zip(positions, residues):\n",
        "                ax2.text(pos, 0.5, res, ha='center', va='center', \n",
        "                        fontsize=8, fontweight='bold')\n",
        "            \n",
        "            ax2.set_xlabel(\"Residue Position\", fontsize=12, fontweight='bold')\n",
        "            ax2.set_ylabel(\"Sequence\", fontsize=10)\n",
        "            ax2.set_ylim(0, 1)\n",
        "            ax2.set_xlim(positions[0]-0.5, positions[-1]+0.5)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            \n",
        "            # Save figure\n",
        "            fig_path = os.path.join(save_dir, f\"{seq_id}_{chain}_enhanced.png\")\n",
        "            plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            \n",
        "            print(f\"üíæ Saved: {fig_path}\")\n",
        "\n",
        "# Run enhanced visualization\n",
        "print(\"üé® Creating enhanced visualizations...\")\n",
        "create_enhanced_visualization()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "file_upload",
      "metadata": {
        "id": "file_upload"
      },
      "source": [
        "## 4. üìÅ Alternative: File Upload\n",
        "\n",
        "If you prefer to upload a file with multiple sequences, use the cell below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "file_upload_interface",
      "metadata": {
        "id": "file_upload_interface"
      },
      "outputs": [],
      "source": [
        "# File upload interface for Colab\n",
        "if IN_COLAB:\n",
        "    print(\"üìÅ Upload your sequence file (CSV, FASTA, or TXT):\")\n",
        "    print(\"\\nSupported formats:\")\n",
        "    print(\"   üìÑ CSV: Seq_ID,Chain_Type,Seq_cap\")\n",
        "    print(\"   üß¨ FASTA: >header\\nsequence\")\n",
        "    print(\"   üìù TXT: one sequence per line\")\n",
        "    \n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        print(f\"\\n‚úÖ File uploaded: {filename}\")\n",
        "        \n",
        "        # Process the uploaded file\n",
        "        try:\n",
        "            df = load_sequences(filename)\n",
        "            print(f\"\\nüìã Uploaded data preview:\")\n",
        "            print(df.head())\n",
        "            \n",
        "            # Run predictions on uploaded file\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_file = f\"output/uploaded_predictions_{timestamp}.csv\"\n",
        "            plot_dir = f\"output/uploaded_plots_{timestamp}\"\n",
        "            \n",
        "            print(f\"\\nüîÆ Running predictions on uploaded data...\")\n",
        "            predict_paradeep(\n",
        "                input_path=filename,\n",
        "                model_H_path=\"models/Best_Model_H.pt\",\n",
        "                model_L_path=\"models/Best_Model_L.pt\",\n",
        "                kernel_H='Full',\n",
        "                kernel_L='Full',\n",
        "                output_path=output_file,\n",
        "                visualize=True,\n",
        "                plot_dir=plot_dir\n",
        "            )\n",
        "            \n",
        "            print(f\"\\n‚úÖ Predictions completed!\")\n",
        "            print(f\"üì• Download your results:\")\n",
        "            files.download(output_file)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing file: {e}\")\n",
        "            print(\"\\nüí° Please check your file format:\")\n",
        "            print(\"   - CSV files need columns: Seq_ID, Chain_Type, Seq_cap\")\n",
        "            print(\"   - Chain_Type should be 'H' or 'L'\")\n",
        "            print(\"   - Sequences should contain only valid amino acids\")\n",
        "    else:\n",
        "        print(\"No file uploaded.\")\n",
        "else:\n",
        "    print(\"üìù File upload widget is only available in Google Colab.\")\n",
        "    print(\"In local environment, place your file in the data/ directory and modify the code above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "Congratulations! You've successfully used ParaDeep to predict paratope residues in your antibody sequences.\n",
        "\n",
        "### Understanding Your Results:\n",
        "- **Binding Residues**: Amino acids predicted to interact with antigens (marked with [brackets])\n",
        "- **Probability Scores**: Confidence levels for each prediction (0.0-1.0)\n",
        "- **Threshold**: 0.5 cutoff for binary classification\n",
        "- **Visualization**: Red bars/dots indicate predicted binding sites\n",
        "\n",
        "### Next Steps:\n",
        "1. **Analyze Results**: Review the binding predictions and visualizations\n",
        "2. **Validate Experimentally**: Compare with known binding data if available\n",
        "3. **Design Experiments**: Use predictions to guide mutagenesis studies\n",
        "4. **Iterate**: Test different antibody variants\n",
        "\n",
        "### Citation\n",
        "If you use ParaDeep in your research, please cite:\n",
        "\n",
        "```\n",
        "ParaDeep: Sequence-Based Paratope Prediction with BiLSTM-CNN\n",
        "GitHub: https://github.com/PiyachatU/ParaDeep\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Thank you for using ParaDeep! üß¨‚ú®**\n",
        "\n",
        "*Happy antibody discovery!* üî¨üéØ\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

